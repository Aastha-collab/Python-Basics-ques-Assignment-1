{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ML - Feature Engineering Assign**"
      ],
      "metadata": {
        "id": "csT3dp0MlP5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is a parameter?**"
      ],
      "metadata": {
        "id": "855YusDPlYCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A parameter is an internal variable learned by a model during training (e.g., weights, biases in neural networks)."
      ],
      "metadata": {
        "id": "rKMe503hl2E8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What is correlation?**\n",
        "\n",
        "**What does negative correlation mean?**"
      ],
      "metadata": {
        "id": "zIT6uAh7l_rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation measures the statistical relationship (strength and direction) between two variables.\n",
        "\n",
        "When one variable increases while the other decreases (e.g., more exercise → lower weight)."
      ],
      "metadata": {
        "id": "Mzae0fsjmJcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Define Machine Learning. What are the main components in Machine Learning?**"
      ],
      "metadata": {
        "id": "J2uQ7zcapQUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML is the study of algorithms that learn from data.\n",
        "Components:\n",
        "\n",
        "- Data\n",
        "\n",
        "- Features\n",
        "\n",
        "- Model\n",
        "\n",
        "- Loss function\n",
        "\n",
        "- Optimizer\n",
        "\n",
        "- Evaluation"
      ],
      "metadata": {
        "id": "oDkdSkILmQOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. How does loss value help in determining whether the model is good or not??**"
      ],
      "metadata": {
        "id": "Yz1X0ckhpViB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss quantifies model errors.\n",
        "\n",
        "Lower loss → better fit."
      ],
      "metadata": {
        "id": "6K1i0P5Pmdbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What are continuous and categorical variables?**"
      ],
      "metadata": {
        "id": "25rvGln8pcXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Continuous: numeric values (e.g., height, salary).\n",
        "\n",
        "- Categorical: discrete categories (e.g., gender, city)."
      ],
      "metadata": {
        "id": "I4Vem6Snmjrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. How do we handle categorical variables in Machine Learning? What are the common techniques??**"
      ],
      "metadata": {
        "id": "qyrlFQTapf6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To handle categorical variables, we must first identify them, then convert them into a numerical format that machine learning algorithms can understand using various encoding techniques, such as One-Hot Encoding, Label Encoding, Target Encoding, and Frequency Encoding\n",
        "\n",
        "Techniques:\n",
        "\n",
        "- Label Encoding\n",
        "\n",
        "- One-Hot Encoding\n",
        "\n",
        "- Ordinal Encoding"
      ],
      "metadata": {
        "id": "RrNO-t3mmj_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What do you mean by training and testing a dataset?**"
      ],
      "metadata": {
        "id": "hUUyTt-opkd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training set: used to teach the model.\n",
        "\n",
        "Testing set: used to evaluate performance on unseen data."
      ],
      "metadata": {
        "id": "0FnSOBDXmkVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What is sklearn.preprocessing?**"
      ],
      "metadata": {
        "id": "ePpegYwxmky7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A module in Scikit-learn with tools for scaling, encoding, normalization, etc."
      ],
      "metadata": {
        "id": "DjpPIb-Hm9aQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is a Test set?**"
      ],
      "metadata": {
        "id": "4XRuuRGNm99S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset portion used to evaluate final model performance."
      ],
      "metadata": {
        "id": "t96sMYEHm-Wx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem??**"
      ],
      "metadata": {
        "id": "FOlkc3R1m-10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data splitting for training and testing machine learning models in Python is typically performed using the train_test_split function from the sklearn.model_selection module."
      ],
      "metadata": {
        "id": "9HitzdTWr742"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "sKNzn0rcnM9k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To approach a machine learning problem, first, clearly define the problem and desired outcome, then collect and prepare the data by cleaning and engineering relevant features. Next, select and train an appropriate ML model, after which you evaluate its performance using metrics and a separate test set. Finally, tune the model's parameters, deploy it, and make predictions on new, unseen data."
      ],
      "metadata": {
        "id": "vtjjR6xUr9Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Why perform EDA before modeling before fitting a model to the data?**"
      ],
      "metadata": {
        "id": "WA3i27a6ny5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand data distribution, detect outliers, handle missing values, and choose the right features.\n",
        "\n",
        "To perform Exploratory Data Analysis (EDA) before fitting a model to understand your data's characteristics, identify patterns, detect errors (like missing values or outliers), and uncover relationships between variables, all of which are critical for effective feature engineering, appropriate model selection, and ultimately building a robust and accurate model."
      ],
      "metadata": {
        "id": "Fh2B95cfnzyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. How can you find correlation between variables in Python?**"
      ],
      "metadata": {
        "id": "m0W8pQhgn3ZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the correlation between variables in Python, the most common and concise methods involve using the pandas library for DataFrames and numpy or scipy.stats for individual arrays.\n",
        "\n",
        "- df.corr(): for a correlation matrix of all numerical columns in a Pandas DataFrame.\n",
        "\n",
        "- scipy.stats.pearsonr(var1, var2): for Pearson correlation and its p-value between two variables.\n",
        "\n",
        "- scipy.stats.spearmanr(var1, var2): for Spearman rank correlation and its p-value between two variables.\n",
        "\n",
        "- numpy.corrcoef(var1, var2): for the correlation matrix of two variables."
      ],
      "metadata": {
        "id": "Kl85QsPstI4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. What is causation? Explain difference between correlation and causation with an example**"
      ],
      "metadata": {
        "id": "JMPFGT9En-tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation: variables move together.\n",
        "\n",
        "Causation: one variable directly affects another.\n",
        "\n",
        "Example: Ice cream sales ↑ and drowning cases ↑\n",
        "correlation due to summer, but no causation.\n",
        "\n",
        "For example, increased ice cream sales and higher crime rates are correlated because they both increase in hot weather, but eating ice cream does not cause crime; the heat is the third, confounding variable"
      ],
      "metadata": {
        "id": "LImuD2KYoBI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. What is an Optimizer? What are different types of optimizers? Explain each with an example.**"
      ],
      "metadata": {
        "id": "KatjJcPIoPPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer updates model parameters to reduce loss.\n",
        "\n",
        "Types:\n",
        "\n",
        "- SGD: updates with small steps.\n",
        "\n",
        "- Momentum: adds previous gradients for faster convergence.\n",
        "\n",
        "- RMSProp: adjusts learning rate based on recent gradients.\n",
        "\n",
        "- Adam: combines momentum + RMSProp (most common)."
      ],
      "metadata": {
        "id": "-6V1LN1-oRPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. What is sklearn.linear_model? What does model.fit() do? What arguments must be given?**"
      ],
      "metadata": {
        "id": "Uu_V7z4coY-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A module for linear models (e.g., LinearRegression, LogisticRegression).\n",
        "\n",
        "Trains the model on training data.\n",
        "\n",
        "Arguments: X_train, y_train."
      ],
      "metadata": {
        "id": "hhneOpz_obiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What does model.predict() do? What arguments must be given?**"
      ],
      "metadata": {
        "id": "H596tfCpodo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generates predictions on new/unseen data.\n",
        "\n",
        "Arguments: X_test."
      ],
      "metadata": {
        "id": "EHG3cKf9od9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is feature scaling? How does it help in Machine Learning?**"
      ],
      "metadata": {
        "id": "ICF6ehg1oeTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature scaling is the process of transforming features (variables) in a dataset to a common scale or range, such as normalizing them to 0-1 or standardizing them to a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "This technique helps machine learning algorithms perform better by preventing features with larger ranges from disproportionately influencing the model, ensuring all features contribute equally."
      ],
      "metadata": {
        "id": "AU_vcDTFoeuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. How do we perform scaling in Python?**"
      ],
      "metadata": {
        "id": "s60CU4IGo3bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "KYxNWo5oo736"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. What is sklearn.preprocessing?**"
      ],
      "metadata": {
        "id": "cscOWjwzvdb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sklearn. preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators."
      ],
      "metadata": {
        "id": "Dd5596c6voli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. Explain data encoding.**"
      ],
      "metadata": {
        "id": "AW-PQ-djo3xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting categorical data into numerical format for ML models.\n",
        "\n",
        "Techniques: One-Hot, Label Encoding, Ordinal Encoding."
      ],
      "metadata": {
        "id": "1Ti7HSiMo4bV"
      }
    }
  ]
}