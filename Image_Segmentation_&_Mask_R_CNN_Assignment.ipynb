{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSrp9o05eVIw2vGY1ZQIx4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aastha-collab/Python-Basics-ques-Assignment-1/blob/main/Image_Segmentation_%26_Mask_R_CNN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Segmentation & Mask R-CNN - Assignment**"
      ],
      "metadata": {
        "id": "0VWMSajXm4AV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: What is TensorFlow Object Detection API (TFOD2) and what are its primary components?**"
      ],
      "metadata": {
        "id": "swWQpjfWm-Ih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TensorFlow Object Detection API (TFOD2) is an open-source framework built on TensorFlow, simplifying the creation, training, and deployment of object detection models with pre-trained models (Model Zoo) and tools, featuring key components like Model Zoo, Pipelines, Configuration Files, Training Scripts, and Export Tools, enabling fast localization and classification in images/videos."
      ],
      "metadata": {
        "id": "dZroNPuhnCmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: Differentiate between semantic segmentation and instance segmentation. Provide examples of where each might be used.**"
      ],
      "metadata": {
        "id": "Fq19qM0GnMfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic segmentation classifies every pixel into a category (e.g., all cars are \"car\"), providing scene understanding, while instance segmentation separates and labels each individual object of a class (e.g., car_1, car_2), enabling object counting and differentiation, crucial for tasks needing object-level precision like autonomous driving or robotics where distinguishing between multiple vehicles is key."
      ],
      "metadata": {
        "id": "-eIoEV0jnQ62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: Explain the Mask R-CNN architecture. How does it extend Faster R-CNN?**"
      ],
      "metadata": {
        "id": "e7Znjce8nZa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mask R-CNN is an extension of Faster R-CNN for instance segmentation, adding a parallel mask prediction branch to output pixel-level masks for each detected object, alongside bounding boxes and class labels, using a shared backbone (like ResNet) for feature extraction, a Region Proposal Network (RPN), and crucial components like Feature Pyramid Networks (FPN) for scale invariance and RoIAlign for precise feature alignment, overcoming pooling inaccuracies for better segmentation quality."
      ],
      "metadata": {
        "id": "oZBgvAeEneWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: Describe the purpose of masks in image segmentation. How are they used during training and inference?**"
      ],
      "metadata": {
        "id": "pL4Uswczn5ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In image segmentation, masks are pixel-level maps identifying regions of interest (ROIs) or objects, crucial for training models to understand what and where things are, acting as ground truth during training (comparing predictions to actual pixel labels) and generating precise object outlines during inference for applications like autonomous driving or medical analysis.\n",
        "\n",
        "During training, models learn to map input images to these target masks, minimizing errors; during inference, the trained model outputs its own predicted masks, often refined to match the input image's size, to segment new images."
      ],
      "metadata": {
        "id": "y8XhSxYJn9l9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5: What are the steps involved in training a custom image segmentation model using TFOD2?**"
      ],
      "metadata": {
        "id": "Fm6ZW0oloFgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a custom image segmentation model using the TensorFlow Object Detection (TFOD) API 2 involves several key steps:\n",
        "\n",
        "The process begins with data collection and annotation, where you gather images and use a tool like LabelMe to create pixel-level segmentation masks for your custom objects.\n",
        "\n",
        "Next, we prepare the dataset by dividing the annotated images into training and testing sets and converting them into the TFRecord format, which is required by the TFOD API. We also need to create a label map file (label_map.pbtxt) that maps class names to numeric IDs.\n",
        "\n",
        "Then, we configure the training pipeline by selecting a pre-trained model (like Mask R-CNN) from the TensorFlow 2 Detection Model Zoo and modifying its configuration file to point to your data, specify the number of classes, and adjust hyperparameters.\n",
        "\n",
        "The next step is to train the model using the configured pipeline and data, monitoring its progress and metrics (like loss) with TensorBoard.\n",
        "\n",
        "After training is complete, we export the trained model's weights to create an inference graph.\n",
        "\n",
        "Finally, we can test the model by running inference on new images to evaluate its performance and visualize the segmentation results."
      ],
      "metadata": {
        "id": "9F858l1boJjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6: Write a Python script to install TFOD2 and verify its installation by printing the available model configs.**"
      ],
      "metadata": {
        "id": "ADxa7pqWo1YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Git Clone Github Project\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# Lets go Inside the Models/research folder\n",
        "%cd models/research\n",
        "\n",
        "!pwd\n",
        "\n",
        "# Protos conversion to python\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Getting the Setup File\n",
        "!cp object_detection/packages/tf2/setup.py ."
      ],
      "metadata": {
        "id": "2VU9B7V-wZKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the Setup\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "z8khUOa-wnWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing other dependencies\n",
        "!pip install tf-models-official"
      ],
      "metadata": {
        "id": "xzIhyRVFxfFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Verification: Print available model configs\n",
        "print(\"\\n--- Verifying Installation: Available Model Configs ---\")\n",
        "config_dir = 'object_detection/configs/tf2'\n",
        "if os.path.exists(config_dir):\n",
        "    configs = [f for f in os.listdir(config_dir) if f.endswith('.config')]\n",
        "    print(f\"Found {len(configs)} model configurations:\")\n",
        "    for cfg in sorted(configs):\n",
        "        print(f\" - {cfg}\")\n",
        "else:\n",
        "    print(\"Error: Model configuration directory not found.\")"
      ],
      "metadata": {
        "id": "7zzhYu01o7DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7: Create a Python script to load a labeled dataset (in TFRecord format) and visualize the annotation masks over the images.**"
      ],
      "metadata": {
        "id": "r27xV42krMKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow opencv-python matplotlib"
      ],
      "metadata": {
        "id": "Xs49yyDgyhGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QbLUz-HDykj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://images.pexels.com/photos/13872248/pexels-photo-13872248.jpeg\"\n",
        "image_path = \"/content/sample_image.jpg\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(image_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"Image downloaded successfully\")"
      ],
      "metadata": {
        "id": "KoDmzMxt1xEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread(image_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VYcZpDg5112k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = \"https://images.pexels.com/photos/13872248/pexels-photo-13872248.jpeg\"\n",
        "img = Image.open(BytesIO(requests.get(url).content))\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wLYXulxa18am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR"
      ],
      "metadata": {
        "id": "EV7wKKfcQNvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TFOD2 and Dependencies\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!pip install .\n",
        "!pip install tf-models-official"
      ],
      "metadata": {
        "id": "AIeQSEphPbWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.*"
      ],
      "metadata": {
        "id": "1GRToBGQOI19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import label_map_util, visualization_utils as viz_utils\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "4HNMNHThOMxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pretrained Model\n",
        "model_name = \"faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\"\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{model_name}.tar.gz\n",
        "!tar -xvf {model_name}.tar.gz"
      ],
      "metadata": {
        "id": "IbTGDs4yOW9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Use pretrained model path\n",
        "PATH_TO_SAVED_MODEL = \"faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8/saved_model\"\n",
        "\n",
        "# 2. Load model\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)"
      ],
      "metadata": {
        "id": "jLjZN4ZbOcIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Use COCO label map (download and place it if needed)\n",
        "category_index = label_map_util.create_category_index_from_labelmap(\n",
        "    \"/content/models/research/object_detection/data/mscoco_label_map.pbtxt\", use_display_name=True\n",
        ")"
      ],
      "metadata": {
        "id": "TB3T2NbyOkJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_image(url, filename):\n",
        "  \"\"\"Downloads an image from a given URL and saves it to a file using requests.\n",
        "\n",
        "  Args:\n",
        "    url: The URL of the image.\n",
        "    filename: The name of the file to save the image to.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Add a User-Agent header to mimic a browser request\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers, stream=True)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "    with open(filename, 'wb') as out_file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            out_file.write(chunk)\n",
        "\n",
        "    print(f\"Image downloaded successfully to {filename}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "\n",
        "# Now call the modified download_image function\n",
        "download_image(\"https://images.pexels.com/photos/13872248/pexels-photo-13872248.jpeg\", \"pexels-photo-13872248.jpg\")"
      ],
      "metadata": {
        "id": "B7wwCkPLOu68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and display the image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "im = cv2.imread(\"/content/pexels-photo-13872248.jpg\")\n",
        "if im is not None:\n",
        "    cv2_imshow(im)\n",
        "else:\n",
        "    print(\"Error: Could not read the image file.\")"
      ],
      "metadata": {
        "id": "3pWrMEiYOzzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Test image path\n",
        "image_path = \"/content/pexels-photo-13872248.jpg\"\n",
        "image_np = cv2.imread(image_path)"
      ],
      "metadata": {
        "id": "JUKDdYXUO2Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Inference\n",
        "input_tensor = tf.convert_to_tensor([image_np], dtype=tf.uint8)\n",
        "\n",
        "detections = detect_fn(input_tensor)"
      ],
      "metadata": {
        "id": "-_5T8Ti6O7F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detections"
      ],
      "metadata": {
        "id": "b0Gfa_lZPAp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Visualization\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    detections['detection_boxes'][0].numpy(),\n",
        "    detections['detection_classes'][0].numpy().astype(np.int32),\n",
        "    detections['detection_scores'][0].numpy(),\n",
        "    category_index,\n",
        "    use_normalized_coordinates=False,\n",
        "    line_thickness=15\n",
        ")\n",
        "# 7. Show image\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.imshow(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CDes7N5HPF9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Show image\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.imshow(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lzzy0JMlPPjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8: Using a pre-trained Mask R-CNN model, write a code snippet to perform inference on a single image and plot the predicted masks.**\n"
      ],
      "metadata": {
        "id": "njhDUKTDs0so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision matplotlib pillow requests"
      ],
      "metadata": {
        "id": "nP5iQZEHuLCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "7OtipmWM_LCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "h-CVIx4tJPoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://images.pexels.com/photos/13872248/pexels-photo-13872248.jpeg\"\n",
        "\n",
        "image = Image.open(BytesIO(requests.get(image_url).content)).convert(\"RGB\")"
      ],
      "metadata": {
        "id": "5uz5l98bJSSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([T.ToTensor()])\n",
        "img_tensor = transform(image)"
      ],
      "metadata": {
        "id": "pSTYZWQaJWtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    predictions = model([img_tensor])"
      ],
      "metadata": {
        "id": "6mYpRdAQJZoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_masks(image, predictions, score_threshold=0.5):\n",
        "    img = np.array(image)\n",
        "    masks = predictions[0]['masks']\n",
        "    scores = predictions[0]['scores']\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    for i in range(len(masks)):\n",
        "        if scores[i] > score_threshold:\n",
        "            mask = masks[i, 0].cpu().numpy()\n",
        "            plt.imshow(mask, alpha=0.4)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "plot_masks(image, predictions)"
      ],
      "metadata": {
        "id": "LqlNGf2pJdxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = \"https://images.pexels.com/photos/13872248/pexels-photo-13872248.jpeg\"\n",
        "img = Image.open(BytesIO(requests.get(url).content))\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gqLr5eDrJ2pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9: Write a Python script to evaluate a trained TFOD2 Mask R-CNN model and plot the Precision-Recall curve.**"
      ],
      "metadata": {
        "id": "W-r8V6aW_2zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "# 1. Path to your COCO ground truth and detection results\n",
        "# You can generate 'detections.json' by running the model on the test set\n",
        "ann_file = 'path/to/kangaroo_coco_annotations.json'\n",
        "det_file = 'path/to/detections.json'\n",
        "\n",
        "def plot_precision_recall_curve(ann_file, det_file):\n",
        "    # Load ground truth and detections\n",
        "    coco_gt = COCO(ann_file)\n",
        "    coco_dt = coco_gt.loadRes(det_file)\n",
        "\n",
        "    # Initialize COCOeval object (iouType='segm' for Mask R-CNN, 'bbox' for boxes)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='segm')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "\n",
        "    # Extract Precision-Recall data\n",
        "    # precision has shape [T, R, K, A, M]\n",
        "    # T: iou thresholds [0.5:0.05:0.95] (index 0 is 0.5)\n",
        "    # R: recall thresholds [0:0.01:1]\n",
        "    # K: categories\n",
        "    # A: area ranges\n",
        "    # M: max detections\n",
        "    precision = coco_eval.eval['precision'][0, :, 0, 0, 2] # IoU=0.5, All recall, Category 0\n",
        "    recall = np.linspace(0, 1, 101)\n",
        "\n",
        "    # Plot the curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, color='blue', lw=2, label='Mask R-CNN (IoU=0.5)')\n",
        "    plt.fill_between(recall, precision, alpha=0.2, color='blue')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve (Mask R-CNN)')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Run the plotting function\n",
        "# plot_precision_recall_curve(ann_file, det_file)"
      ],
      "metadata": {
        "id": "kk7b-umoNs83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: You are working with a city surveillance team to identify illegal parking zones from street camera images. The model you built detects cars using bounding boxes, but the team reports inaccurate overlaps with sidewalks and fails in complex street scenes.\n",
        "How would you refine your model to improve accuracy, especially around object boundaries? What segmentation strategy and tools would you use?**"
      ],
      "metadata": {
        "id": "PxIsfyvmClnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve illegal parking detection around sidewalk boundaries, I would transition from simple bounding boxes to Instance Segmentation using models like Mask R-CNN or YOLOv8/v11, which provide pixel-level masks to accurately delineate cars from sidewalks.\n",
        "\n",
        "To handle complex street scenes, I would employ a multi-task learning strategy that simultaneously segments cars, sidewalks, and curblines, using DeepLabV3+ for high-resolution segmentation.\n",
        "\n",
        "For training, I would utilize semantic segmentation data with polygonal annotations created in Labelbox or V7 Labs, and apply augmentation techniques like random cropping, rotation, and lighting changes to improve robustness against occlusions and varied weather.\n",
        "\n",
        "Finally, I would incorporate a post-processing step to calculate the exact percentage of the car mask overlapping with the labeled sidewalk mask, refining the detection of illegal parking."
      ],
      "metadata": {
        "id": "MV6BKrurCt22"
      }
    }
  ]
}